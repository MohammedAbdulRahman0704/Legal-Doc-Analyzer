Sure! Here's the **updated `README.md`** including instructions to set up a **Python virtual environment (`venv`)** before running the backend and frontend:

---

```markdown
# IntelliDoc Legal Analyzer API

A powerful web application that uses **LLaMA2 (via FastAPI and Ollama)** to analyze legal documents (PDF or text).  
Get **Summaries**, **Key Clauses**, and **Named Entities** extracted from your documents using **AI-powered NLP**.

---

## ğŸš€ Features

- âœ… Upload and display PDF files directly in the browser
- âœ… Extract and analyze legal content using LLaMA2
- âœ… Text input alternative for non-PDF content
- âœ… Categorized analysis: Summary, Key Clauses, Named Entities
- âœ… Clean, collapsible UI with Streamlit
- âœ… FastAPI backend with prompt engineering for legal context

---

## ğŸ—‚ï¸ Project Structure

```

legal-analyzer/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ main.py         # FastAPI backend with LLaMA2 prompts
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py          # Streamlit frontend for file upload and visualization
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md

````

---

## Requirements

### Create and Activate Virtual Environment

Before running the application, it's highly recommended to use a virtual environment:

```bash
# Step 1: Create virtual environment
python -m venv venv

# Step 2: Activate the environment
# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
````

### ğŸ§© Install Required Packages

After activation, install dependencies:

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install fastapi uvicorn requests streamlit PyPDF2
```

---

## ğŸ§  LLaMA2 & Ollama Setup

Ensure [Ollama](https://ollama.com) is installed and LLaMA2 is downloaded:

```bash
# Download and run LLaMA2 model
ollama run llama2
```

---

## â–¶ï¸ How to Run the Project

### Step 1: Start the Backend Server

```bash
cd backend
uvicorn main:app --reload
```

âš ï¸ **Keep this terminal running** â€” it serves the LLaMA2-powered API.

---

### Step 2: Start the Frontend (New Terminal)

Open a **new terminal** while the backend is still running:

```bash
cd frontend
streamlit run app.py
```

---

### Step 3: Use the Application

* Upload a **PDF document** (displayed directly)
* Or paste **legal text**
* Click **Analyze**
* View categorized insights:

  * ğŸ“„ Summary
  * ğŸ“Œ Key Clauses
  * ğŸ” Named Entities

---

## ğŸ§ª Example Screenshot

*(You can add UI screenshots here for a better demo)*

---

## ğŸ”§ Customization

* **Model Name**: Modify `"model": "llama2"` in `main.py`
* **Prompts**: Customize in the `prompts` dictionary for different tasks
* **UI**: Enhance layout or features via Streamlit components

---

## ğŸ›  Technologies Used

* [FastAPI](https://fastapi.tiangolo.com/)
* [Streamlit](https://streamlit.io/)
* [Ollama](https://ollama.com/)
* [Meta LLaMA2](https://ai.meta.com/llama/)
* [PyPDF2](https://pypi.org/project/PyPDF2/)

---

## ğŸ“œ License

This project is for educational and research use only.
AI-generated insights should be verified by qualified legal professionals.

---